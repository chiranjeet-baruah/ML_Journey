{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "holiday-season.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMFZuwLRkImRz90ea/dxGbx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiranjeet14/ML_Projects/blob/master/Competition/holiday_season_detect_objects.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW26s6jy0luK"
      },
      "source": [
        "## Installing dependencies and notebook gpu setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFhhKNCg7rm5"
      },
      "source": [
        "# !pip uninstall -y tensorflow &> /dev/null\n",
        "# !pip install tensorflow &> /dev/null\n",
        "# !pip install --upgrade tensorflow &> /dev/null"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OObaJYLl0q2r"
      },
      "source": [
        "## Importing dependencies for the project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8aFCeQ3F0tP4",
        "outputId": "cbbb9709-14c6-48d1-80ec-cc66d241ce53"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "tf.__version__\n",
        "\n",
        "# from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESbmXn890xvB"
      },
      "source": [
        "## Data download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyRLrYRh0xFM",
        "outputId": "0f5b8f7d-22e5-481c-ac30-51a098de4494"
      },
      "source": [
        "import pathlib\n",
        "dataset_url = \"https://he-s3.s3.amazonaws.com/media/hackathon/hackerearth-deep-learning-challenge-holidays/holiday-season-11-2c924626/14feeca248c811eb.zip\"\n",
        "data_dir = tf.keras.utils.get_file('holiday-season', origin=dataset_url, extract=True)\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "print(\"Data directory : \" + str(data_dir))\n",
        "# sub_directories = [x for x in data_dir.iterdir() if x.is_dir()]\n",
        "# print(sub_directories)\n",
        "# data_dir"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data directory : /root/.keras/datasets/holiday-season\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-_QzrnI8wOe"
      },
      "source": [
        "# data_dir = pathlib.Path(data_dir)\n",
        "# print(\"Data directory : \" + str(data_dir))\n",
        "# # sub_directories = [x for x in data_dir.iterdir() if x.is_dir()]\n",
        "# # print(sub_directories)\n",
        "# # data_dir"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0Fx17AM3ywZ",
        "outputId": "9f326c4d-3ffa-4e4a-9a74-dc9c4e0d419f"
      },
      "source": [
        "data_dir = pathlib.Path('/root/.keras/datasets/dataset')\n",
        "sub_directories = [x for x in data_dir.iterdir() if x.is_dir()]\n",
        "print(sub_directories)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[PosixPath('/root/.keras/datasets/dataset/train'), PosixPath('/root/.keras/datasets/dataset/test')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiwzSqXT36fo",
        "outputId": "c8e1a329-593d-4a65-9177-3f9414417991"
      },
      "source": [
        "train_folder = data_dir.joinpath('train')\n",
        "test_folder = data_dir.joinpath('test')\n",
        "print(\"Train dir : \" + str(train_folder))\n",
        "print(\"Test dir : \" + str(test_folder))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train dir : /root/.keras/datasets/dataset/train\n",
            "Test dir : /root/.keras/datasets/dataset/test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IoqvWDc1MGw",
        "outputId": "593215d5-e3ab-4c08-e790-2aedcfea6fbd"
      },
      "source": [
        "train_files = [e for e in train_folder.iterdir() if e.is_file()]\n",
        "test_files = [e for e in test_folder.iterdir() if e.is_file()]\n",
        "print(\"Train images count : \" + str(len(train_files)))\n",
        "print(\"Test images count : \" + str(len(test_files)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train images count : 6469\n",
            "Test images count : 3489\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LfKlaEkI37uQ",
        "outputId": "4ee58e28-6f75-4262-b573-f154b31828ff"
      },
      "source": [
        "train_csv_path = data_dir.joinpath('train.csv')\n",
        "#test_csv_path = data_dir.joinpath('test.csv')\n",
        "df_train = pd.read_csv(train_csv_path)\n",
        "# df_test = pd.read_csv(test_csv_path)\n",
        "df_train.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>image3476.jpg</td>\n",
              "      <td>Miscellaneous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>image5198.jpg</td>\n",
              "      <td>Candle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>image4183.jpg</td>\n",
              "      <td>Snowman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>image1806.jpg</td>\n",
              "      <td>Miscellaneous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>image7831.jpg</td>\n",
              "      <td>Miscellaneous</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Image          Class\n",
              "0  image3476.jpg  Miscellaneous\n",
              "1  image5198.jpg         Candle\n",
              "2  image4183.jpg        Snowman\n",
              "3  image1806.jpg  Miscellaneous\n",
              "4  image7831.jpg  Miscellaneous"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE2t3x5luBs6"
      },
      "source": [
        "## Creating training and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laUjbA9Ouuqt"
      },
      "source": [
        "IMG_SIZE = (224, 224) # (img_height, img_width)\n",
        "IMG_SHAPE = IMG_SIZE + (3,)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRiGzLjJuC8J",
        "outputId": "021ae1b7-9940-465b-c09e-a240ba9ec2b0"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "preprocess_input = tf.keras.applications.inception_resnet_v2.preprocess_input\n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(#rescale = 1./255,\n",
        "                                                                rotation_range=30,\n",
        "                                                                width_shift_range=0.2,\n",
        "                                                                height_shift_range=0.2,\n",
        "                                                                shear_range = 0.2,\n",
        "                                                                zoom_range = 0.2,\n",
        "                                                                horizontal_flip = True,\n",
        "                                                                vertical_flip = True,\n",
        "                                                                preprocessing_function=preprocess_input,\n",
        "                                                                validation_split=0.08,\n",
        "                                                                )\n",
        "\n",
        "# valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,\n",
        "#                                                                preprocessing_function=preprocess_input,\n",
        "#                                                                )\n",
        "# validation and test images will be similar\n",
        "\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(#rescale = 1./255,\n",
        "                                                               preprocessing_function=preprocess_input,\n",
        "                                                               )\n",
        "\n",
        "# train_generator = train_datagen.flow_from_directory('data/train',\n",
        "#                                                     target_size=IMG_SIZE,\n",
        "#                                                     # color_mode='rgb',\n",
        "#                                                     batch_size=BATCH_SIZE,\n",
        "#                                                     class_mode='categorical',\n",
        "#                                                     shuffle=True,\n",
        "#                                                     )\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(dataframe=df_train,\n",
        "                                                    directory=train_folder,\n",
        "                                                    x_col=\"Image\",\n",
        "                                                    y_col=\"Class\",\n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    shuffle=True,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    target_size=IMG_SIZE,\n",
        "                                                    subset=\"training\",\n",
        "                                                    )\n",
        "\n",
        "validation_generator = train_datagen.flow_from_dataframe(dataframe=df_train,\n",
        "                                                        directory=train_folder,\n",
        "                                                        x_col=\"Image\",\n",
        "                                                        y_col=\"Class\",\n",
        "                                                        batch_size=BATCH_SIZE,\n",
        "                                                        shuffle=True,\n",
        "                                                        class_mode='categorical',\n",
        "                                                        target_size=IMG_SIZE,\n",
        "                                                        subset=\"validation\",\n",
        "                                                        )\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory('/root/.keras/datasets/dataset',\n",
        "                                                  batch_size=10,\n",
        "                                                  # only read images from `test` directory\n",
        "                                                  classes=['test'],\n",
        "                                                  # don't generate labels\n",
        "                                                  class_mode=None,\n",
        "                                                  # don't shuffle\n",
        "                                                  shuffle=False,\n",
        "                                                  # use same size as in training\n",
        "                                                  target_size=IMG_SIZE,\n",
        "                                                  )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5952 validated image filenames belonging to 6 classes.\n",
            "Found 517 validated image filenames belonging to 6 classes.\n",
            "Found 3489 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5an45jia5NPO"
      },
      "source": [
        "## Creating the base model and add some extra layers to adjust to our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2NTTxeZ5Y7l"
      },
      "source": [
        "base_model = tf.keras.applications.InceptionResNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet',\n",
        "                                               )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR8Uwmhn1JRy"
      },
      "source": [
        "### Base model layers to train ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx_M8Y20ALCr"
      },
      "source": [
        "base_model.trainable = True\n",
        "fine_tune_layers = 100"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLvVFzKS0pbL"
      },
      "source": [
        "# if base_model.trainable == True:\n",
        "#   total_base_model_layers = len(base_model.layers)\n",
        "#   print(\"Number of layers in the base model: \", str(total_base_model_layers))\n",
        "\n",
        "#   for layer in base_model.layers[:total_base_model_layers-fine_tune_layers]:\n",
        "#     layer.trainable = False"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JYuBmp4t9-e"
      },
      "source": [
        "x = base_model.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(1024,activation='relu',kernel_regularizer=tf.keras.regularizers.L2(0.03),bias_regularizer=tf.keras.regularizers.L2(0.03))(x)\n",
        "x = tf.keras.layers.Dense(1024,activation='relu',kernel_regularizer=tf.keras.regularizers.L2(0.03),bias_regularizer=tf.keras.regularizers.L2(0.03))(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(1024,activation='relu',kernel_regularizer=tf.keras.regularizers.L2(0.03),bias_regularizer=tf.keras.regularizers.L2(0.03))(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(512,activation='relu',kernel_regularizer=tf.keras.regularizers.L2(0.03),bias_regularizer=tf.keras.regularizers.L2(0.03))(x)\n",
        "x = tf.keras.layers.Dense(512,activation='relu',kernel_regularizer=tf.keras.regularizers.L2(0.03),bias_regularizer=tf.keras.regularizers.L2(0.03))(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(512,activation='relu',kernel_regularizer=tf.keras.regularizers.L2(0.03),bias_regularizer=tf.keras.regularizers.L2(0.03))(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "preds = tf.keras.layers.Dense(6,activation='softmax')(x)\n",
        "model = tf.keras.models.Model(inputs=base_model.input,outputs=preds)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk5ZtD7P7lqy"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEdgQzcf7Hp3"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, epsilon=0.1), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
        "# model.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utGOcbnU7sW7",
        "outputId": "06e09cf8-82b9-4e93-d5fc-be919a78a105"
      },
      "source": [
        "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID = validation_generator.n//validation_generator.batch_size\n",
        "EPOCHS = 100\n",
        "\n",
        "# Save the model according to the conditions\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"test_model.h5\", monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=0, mode='auto')\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks = [checkpoint, early],\n",
        "                    )\n",
        "model.save('model.h5')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "186/186 [==============================] - 135s 623ms/step - loss: 144.4040 - accuracy: 0.3896 - val_loss: 122.2364 - val_accuracy: 0.4375\n",
            "Epoch 2/100\n",
            "186/186 [==============================] - 114s 609ms/step - loss: 115.7780 - accuracy: 0.4328 - val_loss: 97.8602 - val_accuracy: 0.4668\n",
            "Epoch 3/100\n",
            "186/186 [==============================] - 114s 611ms/step - loss: 92.6734 - accuracy: 0.4620 - val_loss: 78.3658 - val_accuracy: 0.5449\n",
            "Epoch 4/100\n",
            "186/186 [==============================] - 114s 609ms/step - loss: 74.1676 - accuracy: 0.5796 - val_loss: 62.7262 - val_accuracy: 0.6406\n",
            "Epoch 5/100\n",
            "186/186 [==============================] - 113s 605ms/step - loss: 59.4068 - accuracy: 0.6598 - val_loss: 50.2982 - val_accuracy: 0.6719\n",
            "Epoch 6/100\n",
            "186/186 [==============================] - 114s 610ms/step - loss: 47.6384 - accuracy: 0.6672 - val_loss: 40.3890 - val_accuracy: 0.6777\n",
            "Epoch 7/100\n",
            "186/186 [==============================] - 114s 609ms/step - loss: 38.2535 - accuracy: 0.6760 - val_loss: 32.4481 - val_accuracy: 0.6816\n",
            "Epoch 8/100\n",
            "186/186 [==============================] - 113s 608ms/step - loss: 30.7131 - accuracy: 0.7030 - val_loss: 26.1290 - val_accuracy: 0.6855\n",
            "Epoch 9/100\n",
            "186/186 [==============================] - 113s 605ms/step - loss: 24.7119 - accuracy: 0.7080 - val_loss: 21.0790 - val_accuracy: 0.7090\n",
            "Epoch 10/100\n",
            "186/186 [==============================] - 113s 605ms/step - loss: 19.9164 - accuracy: 0.7161 - val_loss: 17.0608 - val_accuracy: 0.6973\n",
            "Epoch 11/100\n",
            "186/186 [==============================] - 115s 619ms/step - loss: 16.0985 - accuracy: 0.7128 - val_loss: 13.7597 - val_accuracy: 0.7070\n",
            "Epoch 12/100\n",
            "186/186 [==============================] - 115s 616ms/step - loss: 13.0235 - accuracy: 0.7241 - val_loss: 11.2089 - val_accuracy: 0.7188\n",
            "Epoch 13/100\n",
            "186/186 [==============================] - 117s 627ms/step - loss: 10.5677 - accuracy: 0.7301 - val_loss: 9.1216 - val_accuracy: 0.7207\n",
            "Epoch 14/100\n",
            "186/186 [==============================] - 117s 626ms/step - loss: 8.5991 - accuracy: 0.7316 - val_loss: 7.5259 - val_accuracy: 0.7148\n",
            "Epoch 15/100\n",
            "186/186 [==============================] - 117s 625ms/step - loss: 7.0476 - accuracy: 0.7392 - val_loss: 6.2040 - val_accuracy: 0.7148\n",
            "Epoch 16/100\n",
            "186/186 [==============================] - 115s 615ms/step - loss: 5.7832 - accuracy: 0.7558 - val_loss: 5.1168 - val_accuracy: 0.7363\n",
            "Epoch 17/100\n",
            "186/186 [==============================] - 114s 610ms/step - loss: 4.7873 - accuracy: 0.7704 - val_loss: 4.3235 - val_accuracy: 0.7480\n",
            "Epoch 18/100\n",
            "186/186 [==============================] - 114s 609ms/step - loss: 3.9538 - accuracy: 0.7966 - val_loss: 3.5336 - val_accuracy: 0.8047\n",
            "Epoch 19/100\n",
            "186/186 [==============================] - 114s 609ms/step - loss: 3.2898 - accuracy: 0.8073 - val_loss: 3.0803 - val_accuracy: 0.7656\n",
            "Epoch 20/100\n",
            "186/186 [==============================] - 113s 608ms/step - loss: 2.7725 - accuracy: 0.8116 - val_loss: 2.6246 - val_accuracy: 0.7852\n",
            "Epoch 21/100\n",
            "186/186 [==============================] - 114s 609ms/step - loss: 2.3488 - accuracy: 0.8262 - val_loss: 2.2726 - val_accuracy: 0.7988\n",
            "Epoch 22/100\n",
            "186/186 [==============================] - 113s 606ms/step - loss: 2.0202 - accuracy: 0.8231 - val_loss: 2.0390 - val_accuracy: 0.7832\n",
            "Epoch 23/100\n",
            "186/186 [==============================] - 113s 605ms/step - loss: 1.7522 - accuracy: 0.8229 - val_loss: 1.7385 - val_accuracy: 0.8047\n",
            "Epoch 24/100\n",
            "186/186 [==============================] - 114s 614ms/step - loss: 1.5085 - accuracy: 0.8458 - val_loss: 1.5620 - val_accuracy: 0.7988\n",
            "Epoch 25/100\n",
            "186/186 [==============================] - 114s 611ms/step - loss: 1.3407 - accuracy: 0.8449 - val_loss: 1.4829 - val_accuracy: 0.7988\n",
            "Epoch 26/100\n",
            "186/186 [==============================] - 117s 628ms/step - loss: 1.2178 - accuracy: 0.8453 - val_loss: 1.3436 - val_accuracy: 0.8223\n",
            "Epoch 27/100\n",
            "186/186 [==============================] - 115s 618ms/step - loss: 1.0974 - accuracy: 0.8571 - val_loss: 1.2535 - val_accuracy: 0.7949\n",
            "Epoch 28/100\n",
            "186/186 [==============================] - 114s 613ms/step - loss: 1.0128 - accuracy: 0.8560 - val_loss: 1.1925 - val_accuracy: 0.8086\n",
            "Epoch 29/100\n",
            "186/186 [==============================] - 114s 612ms/step - loss: 0.9204 - accuracy: 0.8696 - val_loss: 1.1127 - val_accuracy: 0.8164\n",
            "Epoch 30/100\n",
            "186/186 [==============================] - 115s 616ms/step - loss: 0.8495 - accuracy: 0.8913 - val_loss: 1.0401 - val_accuracy: 0.8301\n",
            "Epoch 31/100\n",
            "186/186 [==============================] - 114s 612ms/step - loss: 0.7960 - accuracy: 0.8871 - val_loss: 0.9826 - val_accuracy: 0.8379\n",
            "Epoch 32/100\n",
            "186/186 [==============================] - 114s 611ms/step - loss: 0.7500 - accuracy: 0.8945 - val_loss: 1.0386 - val_accuracy: 0.8320\n",
            "Epoch 33/100\n",
            "186/186 [==============================] - 114s 612ms/step - loss: 0.7087 - accuracy: 0.9036 - val_loss: 0.9424 - val_accuracy: 0.8516\n",
            "Epoch 34/100\n",
            "186/186 [==============================] - 114s 611ms/step - loss: 0.6879 - accuracy: 0.9140 - val_loss: 0.9608 - val_accuracy: 0.8340\n",
            "Epoch 35/100\n",
            "186/186 [==============================] - 114s 611ms/step - loss: 0.6623 - accuracy: 0.9255 - val_loss: 0.9740 - val_accuracy: 0.8398\n",
            "Epoch 36/100\n",
            "186/186 [==============================] - 114s 613ms/step - loss: 0.6405 - accuracy: 0.9222 - val_loss: 0.9208 - val_accuracy: 0.8535\n",
            "Epoch 37/100\n",
            "186/186 [==============================] - 115s 617ms/step - loss: 0.6188 - accuracy: 0.9289 - val_loss: 0.9517 - val_accuracy: 0.8555\n",
            "Epoch 38/100\n",
            "186/186 [==============================] - 113s 605ms/step - loss: 0.5990 - accuracy: 0.9340 - val_loss: 0.9159 - val_accuracy: 0.8594\n",
            "Epoch 39/100\n",
            "186/186 [==============================] - 113s 605ms/step - loss: 0.5884 - accuracy: 0.9201 - val_loss: 0.8522 - val_accuracy: 0.8496\n",
            "Epoch 40/100\n",
            "186/186 [==============================] - 113s 606ms/step - loss: 0.5509 - accuracy: 0.9382 - val_loss: 0.8191 - val_accuracy: 0.8730\n",
            "Epoch 41/100\n",
            "186/186 [==============================] - 114s 613ms/step - loss: 0.5379 - accuracy: 0.9451 - val_loss: 0.9096 - val_accuracy: 0.8574\n",
            "Epoch 42/100\n",
            "186/186 [==============================] - 115s 615ms/step - loss: 0.5432 - accuracy: 0.9416 - val_loss: 0.8386 - val_accuracy: 0.8555\n",
            "Epoch 43/100\n",
            "186/186 [==============================] - 114s 612ms/step - loss: 0.5343 - accuracy: 0.9382 - val_loss: 0.8831 - val_accuracy: 0.8535\n",
            "Epoch 44/100\n",
            "186/186 [==============================] - 114s 613ms/step - loss: 0.5127 - accuracy: 0.9477 - val_loss: 0.8074 - val_accuracy: 0.8848\n",
            "Epoch 45/100\n",
            "186/186 [==============================] - 114s 612ms/step - loss: 0.5189 - accuracy: 0.9507 - val_loss: 0.8037 - val_accuracy: 0.8730\n",
            "Epoch 46/100\n",
            "186/186 [==============================] - 115s 615ms/step - loss: 0.5157 - accuracy: 0.9448 - val_loss: 0.8280 - val_accuracy: 0.8633\n",
            "Epoch 47/100\n",
            "186/186 [==============================] - 114s 611ms/step - loss: 0.4982 - accuracy: 0.9551 - val_loss: 0.8483 - val_accuracy: 0.8750\n",
            "Epoch 48/100\n",
            "186/186 [==============================] - 114s 609ms/step - loss: 0.5008 - accuracy: 0.9575 - val_loss: 0.9134 - val_accuracy: 0.8535\n",
            "Epoch 49/100\n",
            "186/186 [==============================] - 113s 607ms/step - loss: 0.4976 - accuracy: 0.9542 - val_loss: 0.8695 - val_accuracy: 0.8730\n",
            "Epoch 50/100\n",
            "186/186 [==============================] - 114s 609ms/step - loss: 0.4909 - accuracy: 0.9584 - val_loss: 0.8080 - val_accuracy: 0.9023\n",
            "Epoch 51/100\n",
            "186/186 [==============================] - 114s 610ms/step - loss: 0.4751 - accuracy: 0.9676 - val_loss: 0.7607 - val_accuracy: 0.8984\n",
            "Epoch 52/100\n",
            "186/186 [==============================] - 114s 614ms/step - loss: 0.4586 - accuracy: 0.9741 - val_loss: 0.9512 - val_accuracy: 0.8633\n",
            "Epoch 53/100\n",
            "186/186 [==============================] - 113s 606ms/step - loss: 0.4746 - accuracy: 0.9650 - val_loss: 0.8807 - val_accuracy: 0.8711\n",
            "Epoch 54/100\n",
            "186/186 [==============================] - 113s 604ms/step - loss: 0.4769 - accuracy: 0.9656 - val_loss: 0.8011 - val_accuracy: 0.8848\n",
            "Epoch 55/100\n",
            "186/186 [==============================] - 113s 605ms/step - loss: 0.4851 - accuracy: 0.9671 - val_loss: 0.8482 - val_accuracy: 0.8945\n",
            "Epoch 56/100\n",
            "186/186 [==============================] - 113s 605ms/step - loss: 0.4591 - accuracy: 0.9733 - val_loss: 0.7762 - val_accuracy: 0.8848\n",
            "Epoch 57/100\n",
            "186/186 [==============================] - 113s 606ms/step - loss: 0.4410 - accuracy: 0.9768 - val_loss: 0.7813 - val_accuracy: 0.8926\n",
            "Epoch 58/100\n",
            "186/186 [==============================] - 113s 606ms/step - loss: 0.4505 - accuracy: 0.9775 - val_loss: 0.8898 - val_accuracy: 0.8613\n",
            "Epoch 59/100\n",
            "186/186 [==============================] - 113s 604ms/step - loss: 0.4466 - accuracy: 0.9755 - val_loss: 0.8596 - val_accuracy: 0.8906\n",
            "Epoch 60/100\n",
            "186/186 [==============================] - 112s 601ms/step - loss: 0.4351 - accuracy: 0.9800 - val_loss: 0.8275 - val_accuracy: 0.8945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ulpq6fYaDBwr"
      },
      "source": [
        "## Predicting on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V3DhOhQDCbl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5062e73-b225-4da8-b8c8-da04b6610d57"
      },
      "source": [
        "predictions = model.predict_generator(test_generator,verbose=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "349/349 [==============================] - 26s 65ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkF3WRc3a2S6"
      },
      "source": [
        "## Predictions to output.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHHuc9OYXuue"
      },
      "source": [
        "test_filenames = []\n",
        "for filename in test_generator.filenames: \n",
        "    filename = filename.replace('test/','')\n",
        "    test_filenames.append(filename)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7bBDqxPU_1A"
      },
      "source": [
        "preds_cls_idx = predictions.argmax(axis=-1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJhR2WdLVJDT"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "idx_to_classes = {v: k for k, v in train_generator.class_indices.items()}\n",
        "preds_classes = np.vectorize(idx_to_classes.get)(preds_cls_idx)\n",
        "filenames_to_classes = list(zip(test_filenames, preds_classes))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5ilnoqFVPCv"
      },
      "source": [
        "# filenames_to_classes"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TucqgTCDZ0CK"
      },
      "source": [
        "data = pd.DataFrame((zip(test_filenames, preds_classes)),columns=['Image','Class'])\n",
        "data.to_csv('output.csv',index=False)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7vFeDFLaIKx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "0f263f2b-361d-4e06-d5c2-6641cce1a40b"
      },
      "source": [
        "df_demo = pd.read_csv('output.csv')\n",
        "df_demo.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>image10.jpg</td>\n",
              "      <td>Miscellaneous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>image100.jpg</td>\n",
              "      <td>Airplane</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>image1013.jpg</td>\n",
              "      <td>Jacket</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>image1014.jpg</td>\n",
              "      <td>Miscellaneous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>image1018.jpg</td>\n",
              "      <td>Christmas_Tree</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Image           Class\n",
              "0    image10.jpg   Miscellaneous\n",
              "1   image100.jpg        Airplane\n",
              "2  image1013.jpg          Jacket\n",
              "3  image1014.jpg   Miscellaneous\n",
              "4  image1018.jpg  Christmas_Tree"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}