{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "churn_rate_prediction.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiranjeet14/ML_Projects/blob/master/Competition/churn_rate_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "respiratory-canal"
      },
      "source": [
        "import sklearn\n",
        "# ^^^ pyforest auto-imports - don't write above this line\n",
        "# # Additional packages\n",
        "# !pip3 install category_encoders > /dev/null\n",
        "!pip3 install pandas_profiling > /dev/null\n",
        "# !pip3 install imbalanced-learn > /dev/null\n",
        "!pip3 install catboost > /dev/null\n",
        "!pip3 install xgboost > /dev/null\n",
        "!pip3 install boto3 > /dev/null\n",
        "!pip3 install lazypredict > /dev/null"
      ],
      "id": "respiratory-canal",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efficient-chuck"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import gc\n",
        "\n",
        "# settings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "gc.enable()"
      ],
      "id": "efficient-chuck",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aging-integer"
      },
      "source": [
        "!mkdir -p /home/jovyan/work/dataset"
      ],
      "id": "aging-integer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "renewable-provision"
      },
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "    session = requests.Session()\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)"
      ],
      "id": "renewable-provision",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caring-pathology"
      },
      "source": [
        "# Calculating Precision, Recall and f1-score\n",
        "def model_score(actual_value,predicted_values):\n",
        "  from sklearn.metrics import confusion_matrix \n",
        "  from sklearn.metrics import accuracy_score \n",
        "  from sklearn.metrics import classification_report \n",
        "  from sklearn.metrics import recall_score\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  \n",
        "  actual = actual_value\n",
        "  predicted = predicted_values\n",
        "  results = confusion_matrix(actual, predicted) \n",
        "  \n",
        "  print('Confusion Matrix :')\n",
        "  print(results) \n",
        "  print('Accuracy Score :',accuracy_score(actual, predicted))\n",
        "  print('Report : ')\n",
        "  print(classification_report(actual, predicted))\n",
        "  print('Recall Score : ')\n",
        "  print(recall_score(actual, predicted))\n",
        "  print('ROC AUC Score : ')\n",
        "  print(roc_auc_score(actual, predicted))"
      ],
      "id": "caring-pathology",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rental-batch"
      },
      "source": [
        "train_file_id = '12M1iRXbgtpON2cDlu0bvwePhgHcc9d9I'\n",
        "test_file_id = '12CnSdigZ1wYDEsVJfD8kWlOrlx38Dt-u'\n",
        "train_file_destination = '/home/jovyan/work/dataset/churn_train.csv'\n",
        "test_file_destination = '/home/jovyan/work/dataset/churn_test.csv'\n",
        "download_file_from_google_drive(train_file_id, train_file_destination)\n",
        "download_file_from_google_drive(test_file_id, test_file_destination)"
      ],
      "id": "rental-batch",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "committed-oregon"
      },
      "source": [
        "rows_to_read = None\n",
        "df_train = pd.read_csv('/home/jovyan/work/dataset/churn_train.csv', na_values=['?', 'Unknown'], nrows=rows_to_read)\n",
        "df_test = pd.read_csv('/home/jovyan/work/dataset/churn_test.csv', na_values=['?', 'Unknown'], nrows=rows_to_read)\n",
        "\n",
        "target_feature = 'churn_risk_score'"
      ],
      "id": "committed-oregon",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "direct-institution"
      },
      "source": [
        "# from pandas_profiling import ProfileReport\n",
        "# report = ProfileReport(df_train, title='Pandas Profiling Report', explorative=True)\n",
        "# report.to_file(\"churn_report.html\")\n",
        "# # report"
      ],
      "id": "direct-institution",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "palestinian-dependence"
      },
      "source": [
        "## Preprocessing"
      ],
      "id": "palestinian-dependence"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "certified-hardware"
      },
      "source": [
        "### Drop unnecessary columns"
      ],
      "id": "certified-hardware"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "infrared-alarm"
      },
      "source": [
        "columns_to_drop = ['customer_id', 'Name', 'security_no', 'referral_id', 'last_visit_time']\n",
        "\n",
        "df_train.drop(columns_to_drop, axis=1, inplace=True, errors='ignore')\n",
        "df_test.drop(columns_to_drop, axis=1, inplace=True, errors='ignore')"
      ],
      "id": "infrared-alarm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "successful-canberra"
      },
      "source": [
        "def preprocess_date(dataFrame, field):\n",
        "    dataFrame[field] = pd.to_datetime(dataFrame[field])\n",
        "    dataFrame['joining_year'] = dataFrame[field].dt.year\n",
        "    dataFrame['joining_month'] = dataFrame[field].dt.month\n",
        "    dataFrame['joining_day'] = dataFrame[field].dt.day\n",
        "    dataFrame['joining_dayOfWeek'] = dataFrame[field].dt.dayofweek\n",
        "    dataFrame['joining_weekdayName'] = dataFrame[field].dt.day_name()\n",
        "    dataFrame['joining_week'] = dataFrame[field].dt.week\n",
        "    dataFrame['joining_weekOfYear'] = dataFrame[field].dt.weekofyear\n",
        "    dataFrame['joining_dayOfYear'] = dataFrame[field].dt.dayofyear\n",
        "    dataFrame['joining_daysInMonth'] = dataFrame[field].dt.days_in_month\n",
        "    return dataFrame"
      ],
      "id": "successful-canberra",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fancy-villa"
      },
      "source": [
        "df_train = preprocess_date(df_train, 'joining_date')\n",
        "df_test = preprocess_date(df_test, 'joining_date')\n",
        "\n",
        "df_train.drop('joining_date', axis=1, inplace=True, errors='ignore')\n",
        "df_test.drop('joining_date', axis=1, inplace=True, errors='ignore')"
      ],
      "id": "fancy-villa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "average-password"
      },
      "source": [
        "def get_categorical_features(dataFrame):\n",
        "    categorical_feats = [\n",
        "        f for f in dataFrame.columns if dataFrame[f].dtype == 'object'\n",
        "    ]\n",
        "    return categorical_feats\n",
        "\n",
        "def get_non_categorical_features(dataFrame, categorical_feats):\n",
        "    non_categorical_features  = [\n",
        "        f for f in dataFrame.columns if f not in categorical_feats\n",
        "    ]\n",
        "    return non_categorical_features\n",
        "\n",
        "def remove_element_from_list(list_of_elements, element):\n",
        "    if element in list_of_elements: list_of_elements.remove(element)\n",
        "    return list_of_elements"
      ],
      "id": "average-password",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "operating-moisture"
      },
      "source": [
        "categorical_features = get_categorical_features(df_train)\n",
        "non_categorical_features = get_non_categorical_features(df_train, categorical_features)\n",
        "non_categorical_features = remove_element_from_list(non_categorical_features, target_feature)"
      ],
      "id": "operating-moisture",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "outside-hacker"
      },
      "source": [
        "# categorical_features"
      ],
      "id": "outside-hacker",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opposed-relation"
      },
      "source": [
        "# non_categorical_features"
      ],
      "id": "opposed-relation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pediatric-harris"
      },
      "source": [
        "def convert_to_categorical(dataFrame, field):\n",
        "    dataFrame[field] = dataFrame[field].astype('category')\n",
        "    return dataFrame\n",
        "\n",
        "def convert_to_numeric(dataFrame, field):\n",
        "    dataFrame[field] = dataFrame[field].apply(pd.to_numeric, errors='coerce')\n",
        "    return dataFrame\n",
        "\n",
        "def imput_to_numeric(dataFrame, field):\n",
        "    return dataFrame"
      ],
      "id": "pediatric-harris",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "identical-violence"
      },
      "source": [
        "df_train = convert_to_categorical(df_train, categorical_features)\n",
        "df_train = convert_to_categorical(df_train, [target_feature])\n",
        "df_train = convert_to_numeric(df_train, non_categorical_features)\n",
        "\n",
        "df_test = convert_to_categorical(df_test, categorical_features)\n",
        "df_test = convert_to_numeric(df_test, non_categorical_features)"
      ],
      "id": "identical-violence",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "homeless-transmission"
      },
      "source": [
        "# df_train.head()"
      ],
      "id": "homeless-transmission",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gentle-jumping"
      },
      "source": [
        "# Check column type\n",
        "# for col in df_train_new.columns:\n",
        "#     print(\"{} : {}\".format(col,df_train_new[col].dtype))"
      ],
      "id": "gentle-jumping",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fatal-locator"
      },
      "source": [
        "# non_categorical_features NAN values\n",
        "# df_train[non_categorical_features].isna().sum()"
      ],
      "id": "fatal-locator",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obvious-guatemala"
      },
      "source": [
        "# categorical_features NAN values\n",
        "# df_train[categorical_features].isna().sum()"
      ],
      "id": "obvious-guatemala",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "recorded-funds"
      },
      "source": [
        "### Replacing categorical_features NaN values"
      ],
      "id": "recorded-funds"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "editorial-gates"
      },
      "source": [
        "# def replace_nan_category(dataFrame, field, new_category):\n",
        "#     available_categories = list(dataFrame[field].value_counts().index)\n",
        "#     if new_category not in available_categories:\n",
        "#         dataFrame[field] = dataFrame[field].cat.add_categories([new_category])\n",
        "#         dataFrame[field].fillna(new_category, inplace=True)\n",
        "#     return dataFrame"
      ],
      "id": "editorial-gates",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "secondary-savannah"
      },
      "source": [
        "# df_train = replace_nan_category(df_train, 'region_category', 'Region Not Specified')\n",
        "# df_train = replace_nan_category(df_train, 'joined_through_referral', 'Not Applicable')\n",
        "# df_train = replace_nan_category(df_train, 'preferred_offer_types', 'Not Applicable')\n",
        "# df_train = replace_nan_category(df_train, 'medium_of_operation', 'Not Applicable')\n",
        "# df_train = replace_nan_category(df_train, 'gender', 'Not Applicable')\n",
        "\n",
        "# df_test = replace_nan_category(df_test, 'region_category', 'Region Not Specified')\n",
        "# df_test = replace_nan_category(df_test, 'joined_through_referral', 'Not Applicable')\n",
        "# df_test = replace_nan_category(df_test, 'preferred_offer_types', 'Not Applicable')\n",
        "# df_test = replace_nan_category(df_test, 'medium_of_operation', 'Not Applicable')\n",
        "# df_test = replace_nan_category(df_test, 'gender', 'Not Applicable')"
      ],
      "id": "secondary-savannah",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unlike-senator"
      },
      "source": [
        "# df_train.head()"
      ],
      "id": "unlike-senator",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "applied-portal"
      },
      "source": [
        "def fill_NaN_values(dataFrame, field, value):\n",
        "    dataFrame[field].fillna(value, inplace=True)\n",
        "    return dataFrame"
      ],
      "id": "applied-portal",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "metallic-guarantee"
      },
      "source": [
        "df_train = fill_NaN_values(df_train, 'region_category', df_train['region_category'].mode()[0])\n",
        "df_train = fill_NaN_values(df_train, 'joined_through_referral', df_train['joined_through_referral'].mode()[0])\n",
        "df_train = fill_NaN_values(df_train, 'preferred_offer_types', df_train['preferred_offer_types'].mode()[0])\n",
        "df_train = fill_NaN_values(df_train, 'medium_of_operation', df_train['medium_of_operation'].mode()[0])\n",
        "df_train = fill_NaN_values(df_train, 'gender', df_train['gender'].mode()[0])\n",
        "\n",
        "df_test = fill_NaN_values(df_test, 'region_category', df_test['region_category'].mode()[0])\n",
        "df_test = fill_NaN_values(df_test, 'joined_through_referral', df_test['joined_through_referral'].mode()[0])\n",
        "df_test = fill_NaN_values(df_test, 'preferred_offer_types', df_test['preferred_offer_types'].mode()[0])\n",
        "df_test = fill_NaN_values(df_test, 'medium_of_operation', df_test['medium_of_operation'].mode()[0])\n",
        "df_test = fill_NaN_values(df_test, 'gender', df_test['gender'].mode()[0])"
      ],
      "id": "metallic-guarantee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "registered-pottery"
      },
      "source": [
        "### Transfroming target_feature"
      ],
      "id": "registered-pottery"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "focused-scheduling",
        "outputId": "f8b9bf02-2d6f-4705-ffd5-de83ccb4ed61"
      },
      "source": [
        "# Replacing -1 in train data with 1\n",
        "df_train[target_feature] = df_train[target_feature].apply(lambda x:1 if x == -1 else 0 if x == 5 else x)\n",
        "df_train[target_feature].unique()"
      ],
      "id": "focused-scheduling",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 0, 3, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "greenhouse-charity",
        "outputId": "59d8c9a1-744e-4a1c-ac56-343bf582d5d6"
      },
      "source": [
        "df_train.head()"
      ],
      "id": "greenhouse-charity",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>region_category</th>\n",
              "      <th>membership_category</th>\n",
              "      <th>joined_through_referral</th>\n",
              "      <th>preferred_offer_types</th>\n",
              "      <th>medium_of_operation</th>\n",
              "      <th>internet_option</th>\n",
              "      <th>days_since_last_login</th>\n",
              "      <th>avg_time_spent</th>\n",
              "      <th>...</th>\n",
              "      <th>churn_risk_score</th>\n",
              "      <th>joining_year</th>\n",
              "      <th>joining_month</th>\n",
              "      <th>joining_day</th>\n",
              "      <th>joining_dayOfWeek</th>\n",
              "      <th>joining_weekdayName</th>\n",
              "      <th>joining_week</th>\n",
              "      <th>joining_weekOfYear</th>\n",
              "      <th>joining_dayOfYear</th>\n",
              "      <th>joining_daysInMonth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18</td>\n",
              "      <td>F</td>\n",
              "      <td>Village</td>\n",
              "      <td>Platinum Membership</td>\n",
              "      <td>No</td>\n",
              "      <td>Gift Vouchers/Coupons</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>Wi-Fi</td>\n",
              "      <td>17</td>\n",
              "      <td>300.63</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>33</td>\n",
              "      <td>33</td>\n",
              "      <td>229</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>32</td>\n",
              "      <td>F</td>\n",
              "      <td>City</td>\n",
              "      <td>Premium Membership</td>\n",
              "      <td>No</td>\n",
              "      <td>Gift Vouchers/Coupons</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>Mobile_Data</td>\n",
              "      <td>16</td>\n",
              "      <td>306.34</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>Monday</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>240</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>F</td>\n",
              "      <td>Town</td>\n",
              "      <td>No Membership</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Gift Vouchers/Coupons</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>Wi-Fi</td>\n",
              "      <td>14</td>\n",
              "      <td>516.16</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2016</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>Friday</td>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>316</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37</td>\n",
              "      <td>M</td>\n",
              "      <td>City</td>\n",
              "      <td>No Membership</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Gift Vouchers/Coupons</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>Mobile_Data</td>\n",
              "      <td>11</td>\n",
              "      <td>53.27</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2016</td>\n",
              "      <td>10</td>\n",
              "      <td>29</td>\n",
              "      <td>5</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>303</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31</td>\n",
              "      <td>F</td>\n",
              "      <td>City</td>\n",
              "      <td>No Membership</td>\n",
              "      <td>No</td>\n",
              "      <td>Credit/Debit Card Offers</td>\n",
              "      <td>Smartphone</td>\n",
              "      <td>Mobile_Data</td>\n",
              "      <td>20</td>\n",
              "      <td>113.13</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2017</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>255</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   age gender region_category  membership_category joined_through_referral  \\\n",
              "0   18      F         Village  Platinum Membership                      No   \n",
              "1   32      F            City   Premium Membership                      No   \n",
              "2   44      F            Town        No Membership                     Yes   \n",
              "3   37      M            City        No Membership                     Yes   \n",
              "4   31      F            City        No Membership                      No   \n",
              "\n",
              "      preferred_offer_types medium_of_operation internet_option  \\\n",
              "0     Gift Vouchers/Coupons             Desktop           Wi-Fi   \n",
              "1     Gift Vouchers/Coupons             Desktop     Mobile_Data   \n",
              "2     Gift Vouchers/Coupons             Desktop           Wi-Fi   \n",
              "3     Gift Vouchers/Coupons             Desktop     Mobile_Data   \n",
              "4  Credit/Debit Card Offers          Smartphone     Mobile_Data   \n",
              "\n",
              "   days_since_last_login  avg_time_spent  ...  churn_risk_score joining_year  \\\n",
              "0                     17          300.63  ...                 2         2017   \n",
              "1                     16          306.34  ...                 1         2017   \n",
              "2                     14          516.16  ...                 0         2016   \n",
              "3                     11           53.27  ...                 0         2016   \n",
              "4                     20          113.13  ...                 0         2017   \n",
              "\n",
              "   joining_month joining_day joining_dayOfWeek joining_weekdayName  \\\n",
              "0              8          17                 3            Thursday   \n",
              "1              8          28                 0              Monday   \n",
              "2             11          11                 4              Friday   \n",
              "3             10          29                 5            Saturday   \n",
              "4              9          12                 1             Tuesday   \n",
              "\n",
              "  joining_week joining_weekOfYear  joining_dayOfYear  joining_daysInMonth  \n",
              "0           33                 33                229                   31  \n",
              "1           35                 35                240                   31  \n",
              "2           45                 45                316                   30  \n",
              "3           43                 43                303                   31  \n",
              "4           37                 37                255                   30  \n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "affiliated-julian"
      },
      "source": [
        "### Label Encoding categorical_features"
      ],
      "id": "affiliated-julian"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "outside-aurora"
      },
      "source": [
        "ref: http://kagglesolutions.com/r/feature-engineering--label-encoding\n",
        "\n",
        "Since we have two different datasets (X_train and X_test) we need to fit it on all of your data otherwise there might be some categories in the test set X_test that were not in the train set X_train and we will get errors.\n",
        "\n",
        "To resolve this issue we will first concatenate X_train and X_test together and then perform label encoding."
      ],
      "id": "outside-aurora"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hidden-maximum"
      },
      "source": [
        "df_train2=df_train.assign(dataType=\"train-data\")\n",
        "df_test2=df_test.assign(dataType=\"test-data\")"
      ],
      "id": "hidden-maximum",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "standard-clearance"
      },
      "source": [
        "# Add an indicator column while concatenating the two dataframes, so we can later seperate them again:\n",
        "df_combined = pd.concat([df_train2, df_test2], ignore_index=True, axis=0)"
      ],
      "id": "standard-clearance",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "premier-reduction"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "label_object = {}\n",
        "for col in categorical_features:\n",
        "    labelencoder = preprocessing.LabelEncoder()\n",
        "    labelencoder.fit(df_combined[col].astype(str))\n",
        "    df_combined[col] = labelencoder.fit_transform(df_combined[col].astype(str))\n",
        "    label_object[col] = labelencoder"
      ],
      "id": "premier-reduction",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bound-glory"
      },
      "source": [
        "# Split data into tain and test\n",
        "df_test, df_train = df_combined[df_combined[\"dataType\"].eq(\"test-data\")], df_combined[df_combined[\"dataType\"].eq(\"train-data\")]\n",
        "\n",
        "# Drop dataType column\n",
        "df_train.drop('dataType', axis=1, inplace=True, errors='ignore')\n",
        "df_test.drop('dataType', axis=1, inplace=True, errors='ignore')"
      ],
      "id": "bound-glory",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "derived-concert",
        "outputId": "72970fe1-8e62-464c-b65b-1a4e1bbdaafc"
      },
      "source": [
        "# Sample inverse_transform\n",
        "label_object['medium_of_operation'].inverse_transform(df_train['medium_of_operation'][:5])"
      ],
      "id": "derived-concert",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Desktop', 'Desktop', 'Desktop', 'Desktop', 'Smartphone'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "studied-establishment"
      },
      "source": [
        "### Checking if the dataset is balanced/imbalanced"
      ],
      "id": "studied-establishment"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sunset-cosmetic"
      },
      "source": [
        "# df_train['churn_risk_score'].value_counts()"
      ],
      "id": "sunset-cosmetic",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phantom-bermuda",
        "outputId": "5b983fd2-0d67-438a-c088-393a9fb35857"
      },
      "source": [
        "# python check if dataset is imbalanced : https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets\n",
        "\n",
        "target_count = df_train['churn_risk_score'].value_counts()\n",
        "target_count.plot(kind='bar', title='Churn Proportions')"
      ],
      "id": "phantom-bermuda",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:title={'center':'Churn Proportions'}>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "defined-public"
      },
      "source": [
        "labels = df_train[target_feature].values\n",
        "df_train.drop(target_feature, axis=1, inplace=True, errors='ignore')\n",
        "df_test.drop(target_feature, axis=1, inplace=True, errors='ignore')"
      ],
      "id": "defined-public",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "outdoor-costs"
      },
      "source": [
        "### Replacing non_categorical_features NaN values - MICE imputation"
      ],
      "id": "outdoor-costs"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dirty-progressive",
        "outputId": "a18e90c9-57a5-4ac2-bf5a-038fe1cbbcae"
      },
      "source": [
        "from sklearn.experimental import enable_iterative_imputer \n",
        "from sklearn.impute import IterativeImputer as MICE\n",
        "\n",
        "# Create a copy of my original dataset\n",
        "dataset_impute = df_train.copy()\n",
        "\n",
        "# Apply MICE\n",
        "dataset_impute_complete = MICE(max_iter=150, verbose=10, random_state=10).fit_transform(dataset_impute.values)\n",
        "\n",
        "# Turning into df again\n",
        "df_train = pd.DataFrame(data=dataset_impute_complete, columns=dataset_impute.columns, index=dataset_impute.index)\n",
        "\n",
        "df_train.head()"
      ],
      "id": "dirty-progressive",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[IterativeImputer] Completing matrix with shape (36992, 27)\n",
            "[IterativeImputer] Ending imputation round 1/150, elapsed time 1.94\n",
            "[IterativeImputer] Change: 113.37127013765223, scaled tolerance: 99.91405 \n",
            "[IterativeImputer] Ending imputation round 2/150, elapsed time 3.74\n",
            "[IterativeImputer] Change: 0.0, scaled tolerance: 99.91405 \n",
            "[IterativeImputer] Early stopping criterion reached.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>region_category</th>\n",
              "      <th>membership_category</th>\n",
              "      <th>joined_through_referral</th>\n",
              "      <th>preferred_offer_types</th>\n",
              "      <th>medium_of_operation</th>\n",
              "      <th>internet_option</th>\n",
              "      <th>days_since_last_login</th>\n",
              "      <th>avg_time_spent</th>\n",
              "      <th>...</th>\n",
              "      <th>feedback</th>\n",
              "      <th>joining_year</th>\n",
              "      <th>joining_month</th>\n",
              "      <th>joining_day</th>\n",
              "      <th>joining_dayOfWeek</th>\n",
              "      <th>joining_weekdayName</th>\n",
              "      <th>joining_week</th>\n",
              "      <th>joining_weekOfYear</th>\n",
              "      <th>joining_dayOfYear</th>\n",
              "      <th>joining_daysInMonth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>300.63</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>31.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>306.34</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>31.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>516.16</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>316.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>53.27</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>303.0</td>\n",
              "      <td>31.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>113.13</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    age  gender  region_category  membership_category  \\\n",
              "0  18.0     0.0              2.0                  3.0   \n",
              "1  32.0     0.0              0.0                  4.0   \n",
              "2  44.0     0.0              1.0                  2.0   \n",
              "3  37.0     1.0              0.0                  2.0   \n",
              "4  31.0     0.0              0.0                  2.0   \n",
              "\n",
              "   joined_through_referral  preferred_offer_types  medium_of_operation  \\\n",
              "0                      0.0                    1.0                  1.0   \n",
              "1                      0.0                    1.0                  1.0   \n",
              "2                      1.0                    1.0                  1.0   \n",
              "3                      1.0                    1.0                  1.0   \n",
              "4                      0.0                    0.0                  2.0   \n",
              "\n",
              "   internet_option  days_since_last_login  avg_time_spent  ...  feedback  \\\n",
              "0              2.0                   17.0          300.63  ...       4.0   \n",
              "1              1.0                   16.0          306.34  ...       5.0   \n",
              "2              2.0                   14.0          516.16  ...       3.0   \n",
              "3              1.0                   11.0           53.27  ...       3.0   \n",
              "4              1.0                   20.0          113.13  ...       3.0   \n",
              "\n",
              "   joining_year  joining_month  joining_day  joining_dayOfWeek  \\\n",
              "0        2017.0            8.0         17.0                3.0   \n",
              "1        2017.0            8.0         28.0                0.0   \n",
              "2        2016.0           11.0         11.0                4.0   \n",
              "3        2016.0           10.0         29.0                5.0   \n",
              "4        2017.0            9.0         12.0                1.0   \n",
              "\n",
              "   joining_weekdayName  joining_week  joining_weekOfYear  joining_dayOfYear  \\\n",
              "0                  4.0          33.0                33.0              229.0   \n",
              "1                  1.0          35.0                35.0              240.0   \n",
              "2                  0.0          45.0                45.0              316.0   \n",
              "3                  2.0          43.0                43.0              303.0   \n",
              "4                  5.0          37.0                37.0              255.0   \n",
              "\n",
              "   joining_daysInMonth  \n",
              "0                 31.0  \n",
              "1                 31.0  \n",
              "2                 30.0  \n",
              "3                 31.0  \n",
              "4                 30.0  \n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "environmental-brazilian",
        "outputId": "d45b094d-160d-499a-d295-f22139a42328"
      },
      "source": [
        "print(\"NaN Values:\",df_train.isna().any().sum())"
      ],
      "id": "environmental-brazilian",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NaN Values: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fixed-arrest",
        "outputId": "fff78f18-e9f5-4930-d6bc-aff932f8bd47"
      },
      "source": [
        "print(\"NaN Values:\",df_test.isna().any().sum())"
      ],
      "id": "fixed-arrest",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NaN Values: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "broken-stage",
        "outputId": "9ebd9800-9541-4f93-a970-b2237441ac4e"
      },
      "source": [
        "df_test.fillna(df_test.mean(), inplace=True)\n",
        "print(\"NaN Values:\",df_test.isna().any().sum())"
      ],
      "id": "broken-stage",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NaN Values: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fatal-picking"
      },
      "source": [
        "# # Check column type\n",
        "# for col in df_train.columns:\n",
        "#     print(\"{} : {}\".format(col,df_train[col].dtype))"
      ],
      "id": "fatal-picking",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "matched-wrapping"
      },
      "source": [
        "### Splitting Data into train-cv"
      ],
      "id": "matched-wrapping"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "retired-destruction"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_cv, y_train, y_cv = train_test_split(df_train, labels, test_size=0.15, shuffle=True)"
      ],
      "id": "retired-destruction",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "transparent-throw"
      },
      "source": [
        "### Scaling data"
      ],
      "id": "transparent-throw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blond-decrease"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_cv_scaled = scaler.transform(X_cv)\n",
        "X_test_scaled = scaler.transform(df_test)"
      ],
      "id": "blond-decrease",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stock-dover"
      },
      "source": [
        "### Modelling & Cross-Validation"
      ],
      "id": "stock-dover"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fitted-copying",
        "outputId": "8c2e9e2f-097c-4d40-ab19-cd108b47f9bf"
      },
      "source": [
        "import sklearn.utils as skutils\n",
        "class_weights = skutils.class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "class_weights"
      ],
      "id": "fitted-copying",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.7571153383096557,\n",
              " 1: 1.950558312655087,\n",
              " 2: 2.7012886597938146,\n",
              " 3: 0.7068225244464427,\n",
              " 4: 0.7238259668508288}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joint-episode"
      },
      "source": [
        "sample_weights = skutils.class_weight.compute_sample_weight('balanced', y_train)\n",
        "# sample_weights"
      ],
      "id": "joint-episode",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "contrary-carter"
      },
      "source": [
        "# # helper functions\n",
        "# import sklearn.metrics as skm\n",
        "# def log1p(vec):\n",
        "#     return np.log1p(abs(vec))\n",
        "\n",
        "# def expm1(x):\n",
        "#     return np.expm1(x)\n",
        "\n",
        "# def clipExp(vec):\n",
        "#     return np.clip(expm1(vec), 0, None)\n",
        "\n",
        "# def printScore(y_train, y_train_pred):\n",
        "#     print(skm.f1_score(y_train, y_train_pred, average=\"macro\"))"
      ],
      "id": "contrary-carter",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "growing-notice"
      },
      "source": [
        "# !pip install hyperopt > /dev/null"
      ],
      "id": "growing-notice",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "through-newfoundland"
      },
      "source": [
        "# from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# space = {'criterion': hp.choice('criterion', ['entropy', 'gini']),\n",
        "#         'max_depth': hp.quniform('max_depth', 10, 12, 10),\n",
        "#         'max_features': hp.choice('max_features', ['auto', 'sqrt','log2', None]),\n",
        "#         'min_samples_leaf': hp.uniform ('min_samples_leaf', 0, 0.5),\n",
        "#         'min_samples_split' : hp.uniform ('min_samples_split', 0, 1),\n",
        "#         'n_estimators' : hp.choice('n_estimators', [10, 50])\n",
        "#     }\n",
        "\n",
        "# def objective(space):\n",
        "#     model = RandomForestClassifier(criterion = space['criterion'], \n",
        "#                                    max_depth = space['max_depth'],\n",
        "#                                  max_features = space['max_features'],\n",
        "#                                  min_samples_leaf = space['min_samples_leaf'],\n",
        "#                                  min_samples_split = space['min_samples_split'],\n",
        "#                                  n_estimators = space['n_estimators'], \n",
        "#                                  )\n",
        "    \n",
        "#     accuracy = cross_val_score(model, X_train_scaled, y_train, cv = 4, n_jobs=-1, verbose=0).mean()\n",
        "\n",
        "#     # We aim to maximize accuracy, therefore we return it as a negative value\n",
        "#     return {'loss': -accuracy, 'status': STATUS_OK }\n",
        "    \n",
        "# trials = Trials()\n",
        "# best = fmin(fn= objective,\n",
        "#             space= space,\n",
        "#             algo= tpe.suggest,\n",
        "#             max_evals = 20,\n",
        "#             trials= trials)\n",
        "# best"
      ],
      "id": "through-newfoundland",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pending-kruger",
        "outputId": "4b410432-d4f1-41ff-8f98-a392b487c0de"
      },
      "source": [
        "# !pip3 install git+https://github.com/hyperopt/hyperopt-sklearn > /dev/null"
      ],
      "id": "pending-kruger",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Running command git clone -q https://github.com/hyperopt/hyperopt-sklearn /tmp/pip-req-build-c0gis9cx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "binding-miller"
      },
      "source": [
        "# from hpsklearn import HyperoptEstimator, any_classifier\n",
        "# from hyperopt import tpe\n",
        "\n",
        "# # Instantiate a HyperoptEstimator with the search space and number of evaluations\n",
        "# estim = HyperoptEstimator( classifier=any_classifier('clf'),  \n",
        "#                             algo=tpe.suggest, trial_timeout=300)\n",
        "\n",
        "# # Search the hyperparameter space based on the data\n",
        "# estim.fit( X_train_scaled, y_train )\n",
        "\n",
        "# # Predicting on CV data\n",
        "# print(\"Accuracy on Test Data: {}\".format(estim.score(X_cv_scaled, y_cv)))\n",
        "# print(estim.best_model())"
      ],
      "id": "binding-miller",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "subtle-raleigh"
      },
      "source": [
        "# import json\n",
        "# print(json.dumps(nested_dict, sort_keys=True, indent=4))"
      ],
      "id": "subtle-raleigh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "terminal-importance"
      },
      "source": [
        "# from pprint import pprint\n",
        "# print(\"Predicting using RandomForest\")\n",
        "# # alg = XGBClassifier\n",
        "# alg = RandomForestClassifier(bootstrap=False, criterion='entropy',\n",
        "#                        max_features=0.34067731242165933, n_estimators=223,\n",
        "#                        n_jobs=1, random_state=4, verbose=False)\n",
        "# alg.fit(X_train_scaled, y_train)\n",
        "# predictions = alg.predict(X_cv_scaled)\n",
        "# # pprint(alg.get_params())"
      ],
      "id": "terminal-importance",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "identified-remains"
      },
      "source": [
        "# model_score(y_cv,predictions)"
      ],
      "id": "identified-remains",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "excited-banks"
      },
      "source": [
        "# !pip3 install lazypredict > /dev/null\n",
        "# from lazypredict.Supervised import LazyClassifier\n",
        "# clf = LazyClassifier(verbose=0,ignore_warnings=True)\n",
        "# models, predictions = clf.fit(X_train_scaled, X_cv, y_train, y_cv)\n",
        "# models"
      ],
      "id": "excited-banks",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "serious-cambodia"
      },
      "source": [
        "# from hyperopt import hp\n",
        "# import numpy as np\n",
        "# from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "# # XGB parameters\n",
        "# xgb_clf_params = {\n",
        "#     'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
        "#     'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
        "#     'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
        "#     'reg_alpha':        hp.choice('reg_alpha',        np.arange(0.1, 1, 0.1)),\n",
        "#     'reg_lambda':       hp.choice('reg_lambda',       np.arange(1, 5, 0.5)),\n",
        "#     'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 1, 0.1)),\n",
        "#     'gamma':            hp.choice('gamma',            np.arange(0.1, 2, 0.1)),\n",
        "#     'subsample':        hp.uniform('subsample', 0.2, 1),\n",
        "#     'n_estimators':     hp.choice('n_estimators',     np.arange(100, 3000, 100, dtype=int)),\n",
        "# }\n",
        "\n",
        "# xgb_fit_params = {\n",
        "#     'eval_metric': 'mlogloss',\n",
        "#     'early_stopping_rounds': 10,\n",
        "#     'verbose': False\n",
        "# }\n",
        "# xgb_para = dict()\n",
        "# xgb_para['clf_params'] = xgb_clf_params\n",
        "# xgb_para['fit_params'] = xgb_fit_params\n",
        "# xgb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))\n",
        "\n",
        "\n",
        "# # LightGBM parameters\n",
        "# lgb_clf_params = {\n",
        "#     'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
        "#     'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
        "#     'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
        "#     'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
        "#     'subsample':        hp.uniform('subsample', 0.8, 1),\n",
        "#     'n_estimators':     100,\n",
        "# }\n",
        "# lgb_fit_params = {\n",
        "# #     'eval_metric': 'l2',\n",
        "#     'early_stopping_rounds': 10,\n",
        "#     'verbose': False\n",
        "# }\n",
        "# lgb_para = dict()\n",
        "# lgb_para['clf_params'] = lgb_clf_params\n",
        "# lgb_para['fit_params'] = lgb_fit_params\n",
        "# lgb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))\n",
        "\n",
        "\n",
        "# # CatBoost parameters\n",
        "# ctb_clf_params = {\n",
        "#     'learning_rate':     hp.choice('learning_rate',     np.arange(0.05, 0.31, 0.05)),\n",
        "#     'max_depth':         hp.choice('max_depth',         np.arange(5, 16, 1, dtype=int)),\n",
        "#     'colsample_bylevel': hp.choice('colsample_bylevel', np.arange(0.3, 0.8, 0.1)),\n",
        "#     'n_estimators':      100,\n",
        "# #     'eval_metric':       'RMSE',\n",
        "# }\n",
        "# ctb_fit_params = {\n",
        "#     'early_stopping_rounds': 10,\n",
        "#     'verbose': False\n",
        "# }\n",
        "# ctb_para = dict()\n",
        "# ctb_para['clf_params'] = ctb_clf_params\n",
        "# ctb_para['fit_params'] = ctb_fit_params\n",
        "# ctb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))"
      ],
      "id": "serious-cambodia",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brave-summary"
      },
      "source": [
        "# import lightgbm as lgb\n",
        "# import xgboost as xgb\n",
        "# import catboost as ctb\n",
        "# from hyperopt import fmin, tpe, STATUS_OK, STATUS_FAIL, Trials\n",
        "\n",
        "\n",
        "# class HPOpt(object):\n",
        "\n",
        "#     def __init__(self, x_train, x_test, y_train, y_test):\n",
        "#         self.x_train = x_train\n",
        "#         self.x_test  = x_test\n",
        "#         self.y_train = y_train\n",
        "#         self.y_test  = y_test\n",
        "\n",
        "#     def process(self, fn_name, space, trials, algo, max_evals):\n",
        "#         fn = getattr(self, fn_name)\n",
        "#         try:\n",
        "#             result = fmin(fn=fn, space=space, algo=algo, max_evals=max_evals, trials=trials)\n",
        "#         except Exception as e:\n",
        "#             return {'status': STATUS_FAIL,\n",
        "#                     'exception': str(e)}\n",
        "#         return result, trials\n",
        "\n",
        "#     def xgb_clf(self, para):\n",
        "#         clf = xgb.XGBClassifier(**para['clf_params'], n_jobs=-1)\n",
        "#         return self.train_clf(clf, para)\n",
        "\n",
        "#     def lgb_clf(self, para):\n",
        "#         clf = lgb.LGBMClassifier(**para['clf_params'], n_jobs=-1)\n",
        "#         return self.train_clf(clf, para)\n",
        "\n",
        "#     def ctb_clf(self, para):\n",
        "#         clf = ctb.CatBoostClassifier(**para['clf_params'], n_jobs=-1)\n",
        "#         return self.train_clf(clf, para)\n",
        "\n",
        "#     def train_clf(self, clf, para):\n",
        "#         clf.fit(self.x_train, self.y_train,\n",
        "#                 eval_set=[(self.x_train, self.y_train), (self.x_test, self.y_test)],\n",
        "#                 **para['fit_params'])\n",
        "#         pred = clf.predict(self.x_test)\n",
        "#         loss = para['loss_func'](self.y_test, pred)\n",
        "#         return {'loss': loss, 'status': STATUS_OK}"
      ],
      "id": "brave-summary",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "after-forwarding"
      },
      "source": [
        "# obj = HPOpt(X_train_scaled, X_cv_scaled, y_train, y_cv)\n",
        "\n",
        "# xgb_opt = obj.process(fn_name='xgb_clf', space=xgb_para, trials=Trials(), algo=tpe.suggest, max_evals=100)\n",
        "# # lgb_opt = obj.process(fn_name='lgb_clf', space=lgb_para, trials=Trials(), algo=tpe.suggest, max_evals=100)\n",
        "# # ctb_opt = obj.process(fn_name='ctb_clf', space=ctb_para, trials=Trials(), algo=tpe.suggest, max_evals=100)"
      ],
      "id": "after-forwarding",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "narrative-quarter"
      },
      "source": [
        "# print(xgb_opt)"
      ],
      "id": "narrative-quarter",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "special-intro",
        "outputId": "13350dd0-c17b-425c-e38c-d70f4bbea8c7"
      },
      "source": [
        "import time\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "clf = xgb.XGBClassifier()\n",
        "\n",
        "\n",
        "# XGB parameters\n",
        "param_grid = {\n",
        "    'learning_rate': np.arange(0.05, 0.31, 0.05),\n",
        "    'subsample': np.arange(0.3, 1, 0.1),\n",
        "    'colsample_bytree': np.arange(0.3, 1, 0.1),\n",
        "    'colsample_bylevel': np.arange(0.3, 1, 0.1),\n",
        "    'max_depth': np.arange(5, 16, 1, dtype=int),\n",
        "    'min_child_weight': np.arange(1, 10, 1, dtype=int),\n",
        "    'reg_alpha': np.arange(0.1, 1, 0.1),\n",
        "    'reg_lambda': np.arange(1, 5, 0.5),\n",
        "    'gamma': np.arange(0.1, 2, 0.1),\n",
        "    'n_estimators': np.arange(100, 3000, 100, dtype=int),\n",
        "}\n",
        "\n",
        "fit_params = {\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'early_stopping_rounds': 10,\n",
        "    'eval_set': [(X_cv_scaled, y_cv)],\n",
        "    'verbose': False\n",
        "}\n",
        "\n",
        "# https://stats.stackexchange.com/questions/431022/error-while-performing-multiclass-classification-using-gridsearch-cv\n",
        "multiclass_scorer = sklearn.metrics.make_scorer(sklearn.metrics.f1_score, average = 'weighted')\n",
        "\n",
        "rs_clf = RandomizedSearchCV(clf,\n",
        "                            param_grid,\n",
        "                            n_iter=50,\n",
        "                            n_jobs=-1,\n",
        "                            verbose=2,\n",
        "                            scoring=multiclass_scorer,\n",
        "                            random_state=42)\n",
        "\n",
        "print(\"Randomized search..\")\n",
        "search_time_start = time.time()\n",
        "rs_clf.fit(X_train_scaled, y_train, **fit_params)\n",
        "print(\"Randomized search time:\", time.time() - search_time_start)\n",
        "\n",
        "best_score = rs_clf.best_score_\n",
        "best_params = rs_clf.best_params_\n",
        "print(\"Best score: {}\".format(best_score))\n",
        "print(\"Best params: \")\n",
        "for param_name in sorted(best_params.keys()):\n",
        "    print('%s: %r' % (param_name, best_params[param_name]))"
      ],
      "id": "special-intro",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Randomized search..\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=-1)]: Done 150 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 11.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Randomized search time: 718.5847144126892\n",
            "Best score: 0.7487969971157384\n",
            "Best params: \n",
            "colsample_bylevel: 0.4\n",
            "colsample_bytree: 0.7000000000000002\n",
            "gamma: 1.9000000000000001\n",
            "learning_rate: 0.1\n",
            "max_depth: 6\n",
            "min_child_weight: 7\n",
            "n_estimators: 200\n",
            "reg_alpha: 0.1\n",
            "reg_lambda: 2.0\n",
            "subsample: 0.7000000000000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "burning-richards"
      },
      "source": [
        "### Predicting on test Data"
      ],
      "id": "burning-richards"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "individual-commissioner"
      },
      "source": [
        "# On test data\n",
        "# trained_model = alg ## Selecting the model to be used\n",
        "trained_model = rs_clf\n",
        "read = pd.read_csv('/home/jovyan/work/dataset/churn_test.csv')\n",
        "predictions_trained_model_test = trained_model.predict(X_test_scaled)\n",
        "# predictions_trained_model_test = estim.predict(X_test_scaled)"
      ],
      "id": "individual-commissioner",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ranking-portuguese",
        "outputId": "9f90d65a-e56a-4a64-ad9c-dc7f9ecac879"
      },
      "source": [
        "submission = pd.DataFrame({\n",
        "        \"customer_id\": read[\"customer_id\"],\n",
        "        \"churn_risk_score\": predictions_trained_model_test\n",
        "    })\n",
        "\n",
        "# revert back 0 to 5 for predictions\n",
        "submission[target_feature] = submission[target_feature].apply(lambda x:5 if x == 0 else x)\n",
        "submission[target_feature].value_counts()"
      ],
      "id": "ranking-portuguese",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.0    6687\n",
              "3.0    5558\n",
              "4.0    4661\n",
              "1.0    1831\n",
              "2.0    1182\n",
              "Name: churn_risk_score, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "organizational-feedback"
      },
      "source": [
        "submission.to_csv('submission.csv', index=False)"
      ],
      "id": "organizational-feedback",
      "execution_count": null,
      "outputs": []
    }
  ]
}